{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset.......\n",
      "Test Dataset.......\n",
      "Multinomial NB:\n",
      "Converting into 32 bins\n",
      "start fitting\n",
      "[[-1.29597585e+03 -1.23411755e+03 -9.83007015e+02 ...  0.00000000e+00\n",
      "  -1.03072610e+03 -5.04612398e+02]\n",
      " [-5.07327793e+02 -3.87466527e+02 -4.33739674e-02 ... -7.74994858e+02\n",
      "  -3.27827321e+02 -7.24241845e+02]\n",
      " [-1.46650532e+03  0.00000000e+00 -6.94855619e+02 ... -8.61087864e+02\n",
      "  -7.64542523e+02 -9.26570026e+02]\n",
      " ...\n",
      " [-1.31679723e+03 -6.52447283e+02 -6.35752225e+02 ... -2.67164545e+02\n",
      "  -1.64467921e+02 -5.47823529e+01]\n",
      " [-5.95137383e+02 -4.56324022e+01 -2.80022992e+02 ... -2.20377822e+02\n",
      "  -7.51589245e+01 -3.28912081e+02]\n",
      " [-5.57201930e+02 -1.47482963e+03 -5.76190986e+02 ... -1.38620183e+03\n",
      "  -1.12676602e+03 -1.04664515e+03]]\n",
      "Accuracy:  81.53 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'online_learning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ff17c2d607c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0mnaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md2_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m \u001b[0monline_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'online_learning' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import struct as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from future.utils import iteritems\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "\n",
    "def plot_images(images,labels):\n",
    "    n_cols = min(5,len(images))\n",
    "    n_rows = len(images) // n_cols\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    \n",
    "    for i in range(n_rows*n_cols):\n",
    "        sp = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(images[i], cmap = plt.cm.gray)\n",
    "        sp.set_title(labels[i])\n",
    "    plt.show()\n",
    "    \n",
    "def convert_pixel(x):\n",
    "    if (x >= 0 and x <= 7):\n",
    "        return 0\n",
    "    elif (x >= 8 and x <= 15):\n",
    "        return 1\n",
    "    elif (x >= 16 and x <= 23):\n",
    "        return 2\n",
    "    elif (x >= 24 and x <= 31):\n",
    "        return 3\n",
    "    elif (x >= 32 and x <= 39):\n",
    "        return 4\n",
    "    elif (x >= 40 and x <= 47):\n",
    "        return 5\n",
    "    elif (x >= 48 and x <= 55):\n",
    "        return 6\n",
    "    elif (x >= 56 and x <= 63):\n",
    "        return 7\n",
    "    elif (x >= 64 and x <= 71):\n",
    "        return 8\n",
    "    elif (x >= 72 and x <= 79):\n",
    "        return 9\n",
    "    elif (x >= 80 and x <= 87):\n",
    "        return 10\n",
    "    elif (x >= 88 and x <= 95):\n",
    "        return 11\n",
    "    elif (x >= 96 and x <= 103):\n",
    "        return 12\n",
    "    elif (x >= 104 and x <= 111):\n",
    "        return 13\n",
    "    elif (x >= 112 and x <= 119):\n",
    "        return 14\n",
    "    elif (x >= 120 and x <= 127):\n",
    "        return 15\n",
    "    elif (x >= 128 and x <= 135):\n",
    "        return 16\n",
    "    elif (x >= 136 and x <= 143):\n",
    "        return 17\n",
    "    elif (x >= 144 and x <= 151):\n",
    "        return 18\n",
    "    elif (x >= 152 and x <= 159):\n",
    "        return 19\n",
    "    elif (x >= 160 and x <= 167):\n",
    "        return 20\n",
    "    elif (x >= 168 and x <= 175):\n",
    "        return 21\n",
    "    elif (x >= 176 and x <= 183):\n",
    "        return 22\n",
    "    elif (x >= 184 and x <= 191):\n",
    "        return 23\n",
    "    elif (x >= 192 and x <= 199):\n",
    "        return 24\n",
    "    elif (x >= 200 and x <= 207):\n",
    "        return 25\n",
    "    elif (x >= 208 and x <= 215):\n",
    "        return 26\n",
    "    elif (x >= 216 and x <= 223):\n",
    "        return 27\n",
    "    elif (x >= 224 and x <= 231):\n",
    "        return 28\n",
    "    elif (x >= 232 and x <= 239):\n",
    "        return 29\n",
    "    elif (x >= 240 and x <= 247):\n",
    "        return 30\n",
    "    elif (x >= 248 and x <= 255):\n",
    "        return 31\n",
    "    \n",
    "def regroup(x, y):\n",
    "    for i in range(60000):\n",
    "        for j in range(784):\n",
    "            x[i][j]=convert_pixel(x[i][j])\n",
    "    for i in range(10000):\n",
    "        for j in range(784):\n",
    "            y[i][j]=convert_pixel(y[i][j])\n",
    "    return x,y\n",
    "\n",
    "#tried doing one by myself but the result is about 33% only, so using API instead\n",
    "class MultinomialNaiveBayes(object):\n",
    "\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        #create look up table\n",
    "        self.count = [0]*10\n",
    "        self.lut = []\n",
    "        for i in range(10):\n",
    "            self.lut.append([])\n",
    "            for j in range(784):\n",
    "                self.lut[i].append([])\n",
    "                for k in range(32):\n",
    "                    self.lut[i][j].append(0)\n",
    "        for i in range(60000):\n",
    "            for j in range(10):\n",
    "                if Y[i] ==j:\n",
    "                    self.count[j]+=1\n",
    "                    class_now = j;\n",
    "            for j in range(784):\n",
    "                self.lut[class_now][j][int(X[i][j])] +=1\n",
    "        #calculate log likelihood prob\n",
    "        for i in range(10):\n",
    "            for j in range(784):\n",
    "                for k in range(32):\n",
    "                    self.lut[i][j][k] /=self.count[i]\n",
    "            self.count[i]  /= 60000\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        logsum = 0.0\n",
    "        m = 0.0\n",
    "        error = 0\n",
    "        for i in range(10000):\n",
    "            for j in range(10):\n",
    "                for k in range(784):\n",
    "                    logsum += self.lut[j][k][int(X[i][k])] + 0.0000000001\n",
    "                #logsum *= np.log(self.count[j])\n",
    "                if logsum >= m:\n",
    "                    m = logsum\n",
    "                    ans = j\n",
    "                #print(logsum\n",
    "                logsum = 0.0\n",
    "            #print(\"Predicted \",ans,\" when it is \",Y[i])\n",
    "            if ans == Y[i]:\n",
    "                error +=1\n",
    "            m = 0.0\n",
    "        print(\"Accuracy: \",error/100,\"%\")\n",
    "            \n",
    "class GaussianNaiveBayes(object):\n",
    "    def fit(self, X, Y, smoothing=1e-2):\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            current_x = X[Y == c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis=0),\n",
    "                'var': current_x.var(axis=0) + smoothing,\n",
    "            }\n",
    "            self.priors[c] = float(len(Y[Y == c])) / len(Y)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        P = self.predict(X)\n",
    "        return np.mean(P == Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        K = len(self.gaussians)\n",
    "        P = np.zeros((N, K))\n",
    "        for c, g in iteritems(self.gaussians):\n",
    "            mean, var = g['mean'], g['var']\n",
    "            P[:,c] = mvn.logpdf(X, mean=mean, cov=var) + np.log(self.priors[c])\n",
    "        #print(P)\n",
    "        return np.argmax(P, axis=1)\n",
    "    \n",
    "def naiveBayes(trainingimage,traininglabel,testingimage,testinglabel,mode):\n",
    "    #0 for discrete, 1 for continuous\n",
    "    if(mode ==0):\n",
    "        print('Multinomial NB:')\n",
    "        print('Converting into 32 bins')\n",
    "        x,y = regroup(trainingimage,testingimage)\n",
    "        print('start fitting')\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(x,traininglabel.ravel())\n",
    "        \n",
    "        print(nb.predict_log_proba(y))\n",
    "        print ('Accuracy: ', nb.score(y,test_labels_array.ravel())*100.0,'%')\n",
    "\n",
    "    else:\n",
    "        print('Gaussian NB: ')\n",
    "        nb = GaussianNaiveBayes()\n",
    "        nb.fit(trainingimage,traininglabel.ravel())\n",
    "        print('Accuracy: ',nb.score(testingimage,testinglabel.ravel())*100.0,'%')\n",
    "        \n",
    "trainingfilenames = {'images' : 'training_set/train-images.idx3-ubyte' ,'labels' : 'training_set/train-labels.idx1-ubyte'}\n",
    "testfilenames = {'images' : 'testing_set/t10k-images.idx3-ubyte' ,'labels' : 'testing_set/t10k-labels.idx1-ubyte'}\n",
    "\n",
    "data_types = {\n",
    "        0x08: ('ubyte', 'B', 1),\n",
    "        0x09: ('byte', 'b', 1),\n",
    "        0x0B: ('>i2', 'h', 2),\n",
    "        0x0C: ('>i4', 'i', 4),\n",
    "        0x0D: ('>f4', 'f', 4),\n",
    "        0x0E: ('>f8', 'd', 8)}\n",
    "\n",
    "#..........................................................For training dataset..............................................................\n",
    "print (\"Training Dataset.......\")\n",
    "for name in trainingfilenames.keys():\n",
    "\tif name == 'images':\n",
    "\t\ttrain_imagesfile = open(trainingfilenames[name],'rb')\n",
    "\tif name == 'labels':\n",
    "\t\ttrain_labelsfile = open(trainingfilenames[name],'rb')\n",
    "\n",
    "train_imagesfile.seek(0)\n",
    "magic = st.unpack('>4B',train_imagesfile.read(4))\n",
    "if(magic[0] and magic[1])or(magic[2] not in data_types):\n",
    "\traise ValueError(\"File Format not correct\")\n",
    "\n",
    "#Information\n",
    "nDim = magic[3]\n",
    "dataType = data_types[magic[2]][0]\n",
    "dataFormat = data_types[magic[2]][1]\n",
    "dataSize = data_types[magic[2]][2]\n",
    "\n",
    "\n",
    "#offset = 0004 for number of images\n",
    "#offset = 0008 for number of rows\n",
    "#offset = 0012 for number of columns\n",
    "#32-bit integer (32 bits = 4 bytes)\n",
    "train_imagesfile.seek(4)\n",
    "nImg = st.unpack('>I',train_imagesfile.read(4))[0] #num of images/labels\n",
    "nR = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n",
    "nC = st.unpack('>I',train_imagesfile.read(4))[0] #num of columns\n",
    "\n",
    "train_labelsfile.seek(8) #Since no. of items = no. of images and is already read\n",
    "\n",
    "#Training set\n",
    "#Reading the labels\n",
    "train_labels_array = np.asarray(st.unpack('>'+dataFormat*nImg,train_labelsfile.read(nImg*dataSize))).reshape((nImg,1))\n",
    "#Reading the Image data\n",
    "nBatch = 10000\n",
    "nIter = int(math.ceil(nImg/nBatch))\n",
    "nBytes = nBatch*nR*nC*dataSize\n",
    "nBytesTot = nImg*nR*nC*dataSize\n",
    "train_images_array = np.array([])\n",
    "for i in range(0,nIter):\n",
    "\ttemp_images_array = 255 - np.asarray(st.unpack('>'+dataFormat*nBytes,train_imagesfile.read(nBytes))).reshape((nBatch,nR,nC))\n",
    "\n",
    "\t#Stacking each nBatch block to form a larger block\n",
    "\tif train_images_array.size == 0:\n",
    "\t\ttrain_images_array = temp_images_array\n",
    "\telse:\n",
    "\t\ttrain_images_array = np.vstack((train_images_array,temp_images_array))\n",
    "\ttemp_images_array = np.array([])\n",
    "\n",
    "\n",
    "#..........................................................For test dataset..................................................................\n",
    "print (\"Test Dataset.......\")\n",
    "for name in testfilenames.keys():\n",
    "\tif name == 'images':\n",
    "\t\ttest_imagesfile = open(testfilenames[name],'rb')\n",
    "\tif name == 'labels':\n",
    "\t\ttest_labelsfile = open(testfilenames[name],'rb')\n",
    "test_imagesfile.seek(0)\n",
    "magic = st.unpack('>4B',test_imagesfile.read(4))\n",
    "if(magic[0] and magic[1])or(magic[2] not in data_types):\n",
    "\traise ValueError(\"File Format not correct\")\n",
    "\n",
    "nDim = magic[3]\n",
    "\n",
    "#offset = 0004 for number of images\n",
    "#offset = 0008 for number of rows\n",
    "#offset = 0012 for number of columns\n",
    "#32-bit integer (32 bits = 4 bytes)\n",
    "test_imagesfile.seek(4)\n",
    "nImg = st.unpack('>I',test_imagesfile.read(4))[0] #num of images/labels\n",
    "nR = st.unpack('>I',test_imagesfile.read(4))[0] #num of rows\n",
    "nC = st.unpack('>I',test_imagesfile.read(4))[0] #num of columns\n",
    "\n",
    "test_labelsfile.seek(8) #Since no. of items = no. of images and is already read\n",
    "#Test set\n",
    "#Reading the labels\n",
    "test_labels_array = np.asarray(st.unpack('>'+dataFormat*nImg,test_labelsfile.read(nImg*dataSize))).reshape((nImg,1))\n",
    "#Reading the Image data\n",
    "nBatch = 10000\n",
    "nIter = int(math.ceil(nImg/nBatch))\n",
    "nBytes = nBatch*nR*nC*dataSize\n",
    "nBytesTot = nImg*nR*nC*dataSize\n",
    "test_images_array = np.array([])\n",
    "for i in range(0,nIter):\n",
    "\ttemp_images_array = 255 - np.asarray(st.unpack('>'+dataFormat*nBytes,test_imagesfile.read(nBytes))).reshape((nBatch,nR,nC))\n",
    "\n",
    "\t#Stacking each nBatch block to form a larger block\n",
    "\tif test_images_array.size == 0:\n",
    "\t\ttest_images_array = temp_images_array\n",
    "\telse:\n",
    "\t\ttest_images_array = np.vstack((test_images_array,temp_images_array))\n",
    "\ttemp_images_array = np.array([])\n",
    "\n",
    "nsamples, nx, ny = train_images_array.shape\n",
    "d2_train_dataset = train_images_array.reshape((nsamples,nx*ny))\n",
    "mtest,mx,my = test_images_array.shape\n",
    "d2_test_dataset = test_images_array.reshape((mtest,mx*my))   \n",
    "\n",
    "     \n",
    "naiveBayes(d2_train_dataset,train_labels_array,d2_test_dataset,test_labels_array,0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In line 1, the alpha and beta for the prior is 1 and 1 respectively.\n",
      "In line 1, the p is 0.5263157894736842\n",
      "In line 1, the binomial likelihood is 0.18089756554150835\n",
      "In line 1, the alpha and beta for the posterior is 11 and 10 respectively.\n",
      "In line 2, the alpha and beta for the prior is 11 and 10 respectively.\n",
      "In line 2, the p is 0.47368421052631576\n",
      "In line 2, the binomial likelihood is 0.12876065177021082\n",
      "In line 2, the alpha and beta for the posterior is 19 and 21 respectively.\n",
      "In line 3, the alpha and beta for the prior is 19 and 21 respectively.\n",
      "In line 3, the p is 0.48214285714285715\n",
      "In line 3, the binomial likelihood is 0.10621385848750886\n",
      "In line 3, the alpha and beta for the posterior is 28 and 30 respectively.\n",
      "In line 4, the alpha and beta for the prior is 28 and 30 respectively.\n",
      "In line 4, the p is 0.4931506849315068\n",
      "In line 4, the binomial likelihood is 0.09307472205046372\n",
      "In line 4, the alpha and beta for the posterior is 37 and 38 respectively.\n",
      "In line 5, the alpha and beta for the prior is 37 and 38 respectively.\n",
      "In line 5, the p is 0.5\n",
      "In line 5, the binomial likelihood is 0.08481349515712312\n",
      "In line 5, the alpha and beta for the posterior is 45 and 45 respectively.\n",
      "In line 6, the alpha and beta for the prior is 45 and 45 respectively.\n",
      "In line 6, the p is 0.5094339622641509\n",
      "In line 6, the binomial likelihood is 0.07732851962742324\n",
      "In line 6, the alpha and beta for the posterior is 55 and 53 respectively.\n",
      "In line 7, the alpha and beta for the prior is 55 and 53 respectively.\n",
      "In line 7, the p is 0.5080645161290323\n",
      "In line 7, the binomial likelihood is 0.07151708889415238\n",
      "In line 7, the alpha and beta for the posterior is 64 and 62 respectively.\n",
      "In line 8, the alpha and beta for the prior is 64 and 62 respectively.\n",
      "In line 8, the p is 0.5106382978723404\n",
      "In line 8, the binomial likelihood is 0.06709008534951119\n",
      "In line 8, the alpha and beta for the posterior is 73 and 70 respectively.\n",
      "In line 9, the alpha and beta for the prior is 73 and 70 respectively.\n",
      "In line 9, the p is 0.5126582278481012\n",
      "In line 9, the binomial likelihood is 0.06339616388889188\n",
      "In line 9, the alpha and beta for the posterior is 82 and 78 respectively.\n",
      "In line 10, the alpha and beta for the prior is 82 and 78 respectively.\n",
      "In line 10, the p is 0.5142857142857142\n",
      "In line 10, the binomial likelihood is 0.060252806339636734\n",
      "In line 10, the alpha and beta for the posterior is 91 and 86 respectively.\n"
     ]
    }
   ],
   "source": [
    "from operator import mul    # or mul=lambda x,y:x*y\n",
    "from fractions import Fraction\n",
    "from functools import reduce\n",
    "\n",
    "def nCr(n,r): \n",
    "  return int( reduce(mul, (Fraction(n-i, i+1) for i in range(r)), 1) )\n",
    "\n",
    "def online_learning(file,a,b):\n",
    "    with open(file) as f:\n",
    "        content = f.readlines()\n",
    "    l=0     #line number\n",
    "    Ht=0    #total heads\n",
    "    Tt=0    #total tails\n",
    "    for line in content:\n",
    "        l+=1\n",
    "        print(\"In line \" + str(l) + \", the alpha and beta for the prior is \" + str(a) + \" and \" + str(b) + \" respectively.\")\n",
    "        H=0  #heads in one line\n",
    "        T=0  #tails in one line\n",
    "        for i in line:\n",
    "            if(i=='1'):\n",
    "                H+=1\n",
    "                Ht+=1\n",
    "            elif(i=='0'):\n",
    "                T+=1\n",
    "                Tt+=1\n",
    "            else:\n",
    "                break\n",
    "        a+=H  #alpha\n",
    "        b+=T  #beta\n",
    "        p=Ht/(Ht+Tt)\n",
    "        print(\"In line \" + str(l) + \", the p is \" + str(p))\n",
    "        binom = nCr(Ht+Tt,Ht)*(p**Ht)*((1-p)**(Tt))\n",
    "        print(\"In line \" + str(l) + \", the binomial likelihood is \" + str(binom))\n",
    "        print(\"In line \" + str(l) + \", the alpha and beta for the posterior is \" + str(a) + \" and \" + str(b) + \" respectively.\")\n",
    "online_learning(\"data.txt\",1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
